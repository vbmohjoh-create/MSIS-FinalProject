{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c786b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moh-j\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as df\n",
    "\n",
    "#load dataset\n",
    "MyDataset=load_dataset(\"KFUPM-JRCAI/arabic-generated-abstracts\");\n",
    "\n",
    "\n",
    "dfby_polishing=df.DataFrame(MyDataset[\"by_polishing\"]);\n",
    "dffrom_title=df.DataFrame(MyDataset[\"from_title\"]);\n",
    "dffrom_title_and_content=df.DataFrame(MyDataset[\"from_title_and_content\"]);\n",
    "\n",
    "\n",
    "features  = [\n",
    "    \"original_abstract\",\n",
    "    \"allam_generated_abstract\",\n",
    "    \"jais_generated_abstract\",\n",
    "    \"llama_generated_abstract\",\n",
    "    \"openai_generated_abstract\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74a6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by_polishing\n",
      "                                                                             0\n",
      "original_abstract          كثيرا ما ارتبطت المصادر التاريخية في الأندلس خ...\n",
      "allam_generated_abstract   يتناول هذا البحث موضوع التعليم بين النساء الأن...\n",
      "jais_generated_abstract    تدرس هذه الدراسة دور المرأة في التعليم في الأن...\n",
      "llama_generated_abstract   يُقدم هذا البحث دراسة شاملة حول حالة التعليم ع...\n",
      "openai_generated_abstract  صور نظام التعليم عند المرأة الأندلسية تستند إل...\n",
      "****************************************************************************************************\n",
      "from_title\n",
      "                                                                             0\n",
      "original_abstract          كثيرا ما ارتبطت المصادر التاريخية في الأندلس خ...\n",
      "allam_generated_abstract   يهدف هذا البحث إلى دراسة نظام التعليم عند المر...\n",
      "jais_generated_abstract    تدرس هذه الورقة البحثية نظام التعليم لدى المرأ...\n",
      "llama_generated_abstract   تهدف هذه الورقة البحثية إلى استكشاف صور نظام ا...\n",
      "openai_generated_abstract  البحث يستكشف نظام التعليم عند المرأة الأندلسية...\n",
      "****************************************************************************************************\n",
      "from_title_and_content \n",
      "                                                                            0\n",
      "original_abstract          كثيرا ما ارتبطت المصادر التاريخية في الأندلس خ...\n",
      "allam_generated_abstract   يتناول هذا البحث موضوع نظام التعليم عند المرأة...\n",
      "jais_generated_abstract    تتناول هذه الدراسة نظام التعليم عند المرأة الأ...\n",
      "llama_generated_abstract   تناولت هذه الدراسة نظام التعليم عند المرأة الأ...\n",
      "openai_generated_abstract  يركز البحث على نظام التعليم للمرأة في الأندلس،...\n",
      "****************************************************************************************************\n",
      "-- Data Size -- \n",
      "\n",
      "the sum of rows  by_polishing\n",
      "  2851\n",
      "****************************************************************************************************\n",
      "the sum of rows inside from_title\n",
      "  2963\n",
      "****************************************************************************************************\n",
      "the sum of rows from_title_and_content\n",
      "  2574\n"
     ]
    }
   ],
   "source": [
    "#Task 1.2\n",
    "\n",
    "#show the dataset structure\n",
    "#print(MyDataset)\n",
    "\n",
    "#print frist row \n",
    "\n",
    "print(\"by_polishing\\n \" ,dfby_polishing.head(1).T)\n",
    "print(\"*\"*100)\n",
    "print(\"from_title\\n \",dffrom_title.head(1).T)\n",
    "print(\"*\"*100)\n",
    "print(\"from_title_and_content \\n\",dffrom_title_and_content.head(1).T)\n",
    "\n",
    "\n",
    "#print size of data :\n",
    "print(\"*\"*100)\n",
    "print(\"-- Data Size -- \\n\")\n",
    "\n",
    "print(\"the sum of rows  by_polishing\\n \" ,len(dfby_polishing))\n",
    "print(\"*\"*100)\n",
    "print(\"the sum of rows inside from_title\\n \" ,len(dffrom_title))\n",
    "print(\"*\"*100)\n",
    "print(\"the sum of rows from_title_and_content\\n \" ,len(dffrom_title_and_content))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58b1e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2851 entries, 0 to 2850\n",
      "Data columns (total 5 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   original_abstract          2851 non-null   object\n",
      " 1   allam_generated_abstract   2851 non-null   object\n",
      " 2   jais_generated_abstract    2851 non-null   object\n",
      " 3   llama_generated_abstract   2851 non-null   object\n",
      " 4   openai_generated_abstract  2851 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 111.5+ KB\n",
      "by_polishing\n",
      "  None\n",
      "****************************************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2963 entries, 0 to 2962\n",
      "Data columns (total 5 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   original_abstract          2963 non-null   object\n",
      " 1   allam_generated_abstract   2963 non-null   object\n",
      " 2   jais_generated_abstract    2963 non-null   object\n",
      " 3   llama_generated_abstract   2963 non-null   object\n",
      " 4   openai_generated_abstract  2963 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 115.9+ KB\n",
      "from_title\n",
      "  None\n",
      "****************************************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2574 entries, 0 to 2573\n",
      "Data columns (total 5 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   original_abstract          2574 non-null   object\n",
      " 1   allam_generated_abstract   2574 non-null   object\n",
      " 2   jais_generated_abstract    2574 non-null   object\n",
      " 3   llama_generated_abstract   2574 non-null   object\n",
      " 4   openai_generated_abstract  2574 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 100.7+ KB\n",
      "from_title_and_content \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#Task 1.3 Load and inspect the dataset structure (columns, data types).\n",
    "\n",
    "print(\"by_polishing\\n \" ,dfby_polishing.info())\n",
    "print(\"*\"*100)\n",
    "print(\"from_title\\n \",dffrom_title.info())\n",
    "print(\"*\"*100)\n",
    "print(\"from_title_and_content \\n\",dffrom_title_and_content.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Dataset :  by_polishing\n",
      "HumanCount :  2851\n",
      "AIgeneratedCount :  11404\n",
      "totlarows  14255\n",
      "humanRatio  20.0 %\n",
      "aiRation   80.0 %\n",
      "****************************************************************************************************\n",
      " The Dataset :  from_title\n",
      "HumanCount :  2963\n",
      "AIgeneratedCount :  11852\n",
      "totlarows  14815\n",
      "humanRatio  20.0 %\n",
      "aiRation   80.0 %\n",
      "****************************************************************************************************\n",
      " The Dataset :  from_title_and_content\n",
      "HumanCount :  2574\n",
      "AIgeneratedCount :  10296\n",
      "totlarows  12870\n",
      "humanRatio  20.0 %\n",
      "aiRation   80.0 %\n",
      "****************************************************************************************************\n",
      "Distribution For All\n",
      "\n",
      "Total Human absracts : 8388\n",
      "Total AI absracts : 33552\n",
      "TotalCount: 41940\n",
      "HumanRatioAllDataset: 20.0 %\n",
      "AIatioAllDataset: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "#task 1.3 -Check the distribution of the target variable (label: human vs. AIgenerated).\n",
    "\n",
    "\n",
    "# for by_polishing\n",
    "# HumanCount=dfby_polishing[\"original_abstract\"].notnull().sum()\n",
    "# allam_generated_abstract=dfby_polishing[\"allam_generated_abstract\"].notnull().sum()\n",
    "# jais_generated_abstract=dfby_polishing[\"jais_generated_abstract\"].notnull().sum()\n",
    "# llama_generated_abstract=dfby_polishing[\"llama_generated_abstract\"].notnull().sum()\n",
    "# openai_generated_abstract=dfby_polishing[\"openai_generated_abstract\"].notnull().sum()\n",
    "\n",
    "#AICount=allam_generated_abstract+jais_generated_abstract+llama_generated_abstract+openai_generated_abstract\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# features = [\n",
    "#     \"original_abstract\",\n",
    "#     \"allam_generated_abstract\",\n",
    "#     \"jais_generated_abstract\",\n",
    "#     \"llama_generated_abstract\",\n",
    "#     \"openai_generated_abstract\"\n",
    "# ]\n",
    "\n",
    "\n",
    "totlarows=0\n",
    "def countHumanVsAIgenerated(df,datasetName):\n",
    "    print(\" The Dataset : \",datasetName)\n",
    "\n",
    "    HumanCount=df[\"original_abstract\"].notnull().sum()\n",
    "    \n",
    "    AIgeneratedCount=0\n",
    "    for fe in features[1:]:\n",
    "       AIgeneratedCount+=df[fe].notnull().sum()\n",
    "\n",
    "\n",
    "    print(\"HumanCount : \",HumanCount)\n",
    "    print(\"AIgeneratedCount : \",AIgeneratedCount)\n",
    "    totlarows=HumanCount+AIgeneratedCount\n",
    "    humanRatio=HumanCount/totlarows *100\n",
    "    aiRatio=AIgeneratedCount/totlarows *100\n",
    "    print(\"totlarows \",totlarows)\n",
    "    print(\"humanRatio \",humanRatio,\"%\")\n",
    "    print(\"aiRation  \",aiRatio,\"%\")\n",
    "\n",
    "\n",
    "countHumanVsAIgenerated(dfby_polishing, \"by_polishing\")\n",
    "print(\"*\"*100)\n",
    "countHumanVsAIgenerated(dffrom_title, \"from_title\")\n",
    "print(\"*\"*100)\n",
    "countHumanVsAIgenerated(dffrom_title_and_content, \"from_title_and_content\")\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"Distribution For All\\n\")\n",
    "humanTotal = len(dfby_polishing) + len(dffrom_title) + len(dffrom_title_and_content)\n",
    "\n",
    "AITotal = humanTotal * 4\n",
    "\n",
    "\n",
    "TotalCount=humanTotal+AITotal;\n",
    "print(\"Total Human absracts :\", humanTotal)\n",
    "print(\"Total AI absracts :\", AITotal)\n",
    "print(\"TotalCount:\", TotalCount)\n",
    "\n",
    "HumanRatioAllDataset=humanTotal/TotalCount*100\n",
    "AIatioAllDataset=AITotal/TotalCount*100\n",
    "\n",
    "print(\"HumanRatioAllDataset:\", HumanRatioAllDataset,\"%\")\n",
    "print(\"AIatioAllDataset:\", AIatioAllDataset,\"%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4022e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Dataset : by_polishing\n",
      "****************************************************************************************************\n",
      "Missing values \n",
      " original_abstract            0\n",
      "allam_generated_abstract     0\n",
      "jais_generated_abstract      0\n",
      "llama_generated_abstract     0\n",
      "openai_generated_abstract    0\n",
      "dtype: int64\n",
      "Duplicated in by_polishing\n",
      "Duplicated  rows  0\n",
      "Duplicated in Feature in original_abstract   0\n",
      "Duplicated in Feature in allam_generated_abstract   0\n",
      "Duplicated in Feature in jais_generated_abstract   0\n",
      "Duplicated in Feature in llama_generated_abstract   0\n",
      "Duplicated in Feature in openai_generated_abstract   0\n",
      "****************************************************************************************************\n",
      "Dataset : from_title\n",
      "****************************************************************************************************\n",
      "Missing values \n",
      " original_abstract            0\n",
      "allam_generated_abstract     0\n",
      "jais_generated_abstract      0\n",
      "llama_generated_abstract     0\n",
      "openai_generated_abstract    0\n",
      "dtype: int64\n",
      "Duplicated in from_title\n",
      "Duplicated  rows  0\n",
      "Duplicated in Feature in original_abstract   0\n",
      "Duplicated in Feature in allam_generated_abstract   0\n",
      "Duplicated in Feature in jais_generated_abstract   0\n",
      "Duplicated in Feature in llama_generated_abstract   0\n",
      "Duplicated in Feature in openai_generated_abstract   0\n",
      "****************************************************************************************************\n",
      "Dataset : from_title_and_content\n",
      "****************************************************************************************************\n",
      "Missing values \n",
      " original_abstract            0\n",
      "allam_generated_abstract     0\n",
      "jais_generated_abstract      0\n",
      "llama_generated_abstract     0\n",
      "openai_generated_abstract    0\n",
      "dtype: int64\n",
      "Duplicated in from_title_and_content\n",
      "Duplicated  rows  0\n",
      "Duplicated in Feature in original_abstract   0\n",
      "Duplicated in Feature in allam_generated_abstract   0\n",
      "Duplicated in Feature in jais_generated_abstract   3\n",
      "Duplicated in Feature in llama_generated_abstract   0\n",
      "Duplicated in Feature in openai_generated_abstract   0\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Task 1.3 Assess data quality: check for missing values, duplicates, and inconsistencies.\n",
    "\n",
    "\n",
    "# 1- missing values\n",
    "# 2- duplicates values\n",
    "\n",
    "def CheckMissingِAndDuplicatedData(df,datasetName):\n",
    "\n",
    "\n",
    "   print(\"Dataset :\",datasetName)\n",
    "   print(\"*\"*100)\n",
    "   print(\"Missing values \\n\" ,df.isnull().sum())\n",
    "   print(\"Duplicated in\",datasetName)\n",
    "\n",
    "   print(\"Duplicated  rows \" ,df.duplicated().sum())\n",
    "   for fe in features:\n",
    "    DuplicatedInFeature=df[fe].duplicated().sum()\n",
    "    print(f\"Duplicated in Feature in\",fe ,\" \" ,DuplicatedInFeature)\n",
    "print(\"*\"*100)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "CheckMissingِAndDuplicatedData(dfby_polishing, \"by_polishing\")\n",
    "print(\"*\"*100)\n",
    "CheckMissingِAndDuplicatedData(dffrom_title, \"from_title\")\n",
    "print(\"*\"*100)\n",
    "CheckMissingِAndDuplicatedData(dffrom_title_and_content, \"from_title_and_content\")\n",
    "\n",
    "print(\"*\"*100)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e3018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  \tby_polishing:\n",
      "Number of Whitespace   0\n",
      "Number of numeric   0\n",
      "****************************************************************************************************\n",
      "Dataset  \tfrom_title:\n",
      "Number of Whitespace   0\n",
      "Number of numeric   0\n",
      "****************************************************************************************************\n",
      "Dataset  \tfrom_title_and_content:\n",
      "Number of Whitespace   0\n",
      "Number of numeric   0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Task 1.3 Assess data quality: check for missing values, duplicates, and inconsistencies.\n",
    "\n",
    "#3- inconsistencies\n",
    " \n",
    "def checkInconsistencies(df, dataset_name):\n",
    "    print(f\"Dataset  \\t{dataset_name}:\")\n",
    "\n",
    "     \n",
    "    for fe in features:\n",
    "     \n",
    "     texts = df[fe].astype(str)\n",
    "    EmptyCount = (texts == \" \").sum()\n",
    "    NumbersCount = texts.str.isnumeric().sum()\n",
    " \n",
    "    print(\"Number of Whitespace  \",EmptyCount)\n",
    "    print(\"Number of numeric  \",NumbersCount)\n",
    " \n",
    "\n",
    "\n",
    "checkInconsistencies(dfby_polishing, \"by_polishing\")\n",
    "print(\"*\"*100)\n",
    "checkInconsistencies(dffrom_title, \"from_title\")\n",
    "print(\"*\"*100)\n",
    "checkInconsistencies(dffrom_title_and_content, \"from_title_and_content\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
